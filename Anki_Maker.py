'''
3.1æ–°åŠŸèƒ½
- å¯¹äºæå–æ–‡ä»¶çš„ç”Ÿè¯çš„åŠŸèƒ½:å¢åŠ äº†å¯¹txt,PDF,wordçš„æ”¯æŒ

3.0æ–°åŠŸèƒ½
- å¢åŠ äº†ä¸€ä¸ªå…¨æ–°çš„åŠŸèƒ½:è‡ªåŠ¨æå–ä¸€ä¸ªmdæ–‡ä»¶é‡Œé¢çš„ç”Ÿè¯(ç”Ÿè¯æŒ‡çš„æ˜¯,ç‰›æ´¥3000è¯ä»¥å¤–,é«˜è€ƒè‹±è¯­3500ä»¥å¤–,ä»¥åŠä¸€äº›åŸºç¡€çš„è¯æ±‡),ç„¶ååˆ¶ä½œä¸ºè¯æ¡
- è§£å†³äº†æ¯æ¬¡æ‰“å¼€è½¯ä»¶éƒ½è¦æ±‚å¯¼å…¥è¯å…¸çš„é—®é¢˜
- è§£å†³äº†ä¸€ä¸ªå°BUG

2.4æ–°åŠŸèƒ½
- åŠ å¿«äº†è½¯ä»¶çš„å¯åŠ¨é€Ÿåº¦
- å¢åŠ äº†"å¯¼å…¥è¯å…¸"çš„åŠŸèƒ½,é˜²æ­¢è¯å…¸æ²¡æ‰¾åˆ°
- ä¼˜åŒ–äº†æŒ‰é’®çš„æ’å¸ƒ
- ç¾åŒ–äº†"ä½¿ç”¨æ•™ç¨‹"

2.3æ–°åŠŸèƒ½
- æ”¯æŒCommand/Control+Enteråœ¨"é‡Šä¹‰"å’Œ"åŠ©è®°"æ¡†æ¢è¡Œ.
- å¢åŠ äº†"æ•™ç¨‹".
- ä¿®å¤äº†éŸ³æ ‡çš„è‡ªåŠ¨è¡¥é½çš„åŠŸèƒ½


2.2æ–°åŠŸèƒ½:
- å¢åŠ äº†å‰ªè´´æ¿çš„ç›‘å¬åŠŸèƒ½.
- å½“æ‰“å¼€æ­¤åŠŸèƒ½çš„æ—¶å€™,å°†ä¼šå¼€å§‹ç›‘å¬å‰ªè´´æ¿.
- å½“è¯†åˆ«åˆ°"å•ä¸ª"çš„"è‹±æ–‡å•è¯"çš„æ—¶å€™,å°†ä¼šä¿å­˜ä¸‹æ¥,å¹¶ä¸”è‡ªåŠ¨å¡«å……éŸ³æ ‡/è¯æ€§/é‡Šä¹‰.
- ä¹‹ååœ¨Macä¸Šä¼šå‘é€ä¼˜é›…çš„AppleScripté€šçŸ¥,ä¸æ‰“æ‰°æˆ‘ä»¬çš„é˜…è¯».
'''

#!/usr/bin/env python3
# anki_vocab_app_enhanced.py

import os
import sys
import json
import csv
import subprocess
import threading
import time
from datetime import datetime
import re
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import genanki
from plyer import notification
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
import re
import tkinter.scrolledtext as scrolledtext  # æ·»åŠ è¿™è¡Œå¯¼å…¥
import chardet  # éœ€è¦å®‰è£…ï¼špip install chardet


# optional genanki for apkg export
try:
    import genanki
except Exception:
    genanki = None


EXPORT_FOLDER = "exports"
DATA_FILE = "draft.json"
DEFAULT_DICT = "dict.json"
AUTOSAVE_INTERVAL = 5  # seconds

CJK_RE = re.compile(r'[\u4e00-\u9fff]')
POS_PREFIX_RE = re.compile(r'^\s*([a-zA-Z]{1,6})\.\s*')


TUTORIAL_CONTENTS = [
    {
        "title": "åŸºæœ¬ä»‹ç»",
        "content": "Anki Maker æ˜¯ä¸€æ¬¾å¸®åŠ©ä½ å¿«é€Ÿåˆ¶ä½œè‹±è¯­å•è¯å¡çš„å·¥å…·ï¼Œæ”¯æŒè‡ªåŠ¨è¡¥å…¨å•è¯ä¿¡æ¯ã€å¯¼å‡ºå¤šç§æ ¼å¼ï¼ˆåŒ…æ‹¬Ankiæ”¯æŒçš„APKGï¼‰ã€‚\n\nä¸»è¦åŠŸèƒ½ï¼š\n- æ‰‹åŠ¨æ·»åŠ å•è¯åŠé‡Šä¹‰\n- ä»å‰ªè´´æ¿è‡ªåŠ¨æ•è·è‹±æ–‡å•è¯\n- è‡ªåŠ¨è¡¥å…¨å•è¯éŸ³æ ‡å’Œé‡Šä¹‰\n- å¯¼å‡ºä¸ºCSV/JSON/APKG/Markdown"
    },
    {
        "title": "æ‰‹åŠ¨æ·»åŠ å•è¯",
        "content": "1.åœ¨ä¸Šæ–¹è¾“å…¥æ¡†ä¾æ¬¡å¡«å†™ï¼šå•è¯ã€è¯æ€§ã€é‡Šä¹‰å’ŒåŠ©è®°.\n ps:å½“æˆ‘ä»¬å¡«å®Œä¸€ä¸ªæ¡†æ¡†ä¹‹å,æŒ‰ä¸‹'Enter'é”®,ä¾¿å¯ä»¥è·³è½¬åˆ°ä¸‹ä¸€ä¸ªæ¡†æ¡†.è¿™æ˜¯æˆ‘å–œæ¬¢çš„.\n\n2.ç‚¹å‡»ã€Œâ• æ·»åŠ è¯æ¡ã€æŒ‰é’®æˆ–æŒ‰å›è½¦å®Œæˆæ·»åŠ \n\n3.æ·»åŠ çš„å•è¯ä¼šæ˜¾ç¤ºåœ¨ä¸‹æ–¹åˆ—è¡¨ä¸­\n\n4.æ¯”è¾ƒè´´å¿ƒçš„æ˜¯æˆ‘ä»¬ä¸éœ€è¦å¡«å†™éŸ³æ ‡.ç¨‹åºä¼šè°ƒç”¨æœ¬åœ°è¯å…¸è‡ªåŠ¨è¡¥å…¥\5å¦‚æœè¦æ¢è¡Œ,åˆ™æŒ‰ä¸‹'Commandæˆ–Control + Enterå›è½¦'"
    },
    {
        "title": "è‡ªåŠ¨è¡¥å…¨åŠŸèƒ½",
        "content": "1.è¾“å…¥å•è¯çš„è‹±æ–‡åï¼Œç‚¹å‡»ã€ŒğŸ”è‡ªåŠ¨è¡¥å…¨ã€æŒ‰é’®ï¼ˆæˆ–æŒ‰Ctrl+E/Cmd+Eï¼‰\n\n2.ç³»ç»Ÿä¼šä»æœ¬åœ°è¯å…¸(dict.json)è‡ªåŠ¨å¡«å……éŸ³æ ‡ã€è¯æ€§å’Œé‡Šä¹‰,éšåè·³è½¬åˆ°'åŠ©è®°'è¿™ä¸ªæ¡†æ¡†.\n\n3.ä½ å¯ä»¥åœ¨è‡ªåŠ¨å¡«å……åæ‰‹åŠ¨ä¿®æ”¹å†…å®¹"
    },
    {
        "title": "å‰ªè´´æ¿ç›‘å¬",
        "content": "1.ç‚¹å‡»ã€ŒğŸ“‹ å¼€å§‹/ç»“æŸç›‘å¬å‰ªè´´æ¿ã€æŒ‰é’®å¼€å¯åŠŸèƒ½\n\n2.å½“å¤åˆ¶å•ä¸ªè‹±æ–‡å•è¯æ—¶ï¼Œç¨‹åºä¼šè‡ªåŠ¨ï¼š\n   - è¯†åˆ«å•è¯å¹¶å¡«å……åˆ°è¾“å…¥æ¡†\n   - è‡ªåŠ¨è¡¥å…¨å•è¯ä¿¡æ¯\n   - è‡ªåŠ¨æ·»åŠ åˆ°åˆ—è¡¨\n\n3.å†æ¬¡ç‚¹å‡»æŒ‰é’®å¯å…³é—­ç›‘å¬"
    },
    {
        "title": "å¯¼å‡ºåŠŸèƒ½",
        "content": "1.å®Œæˆå•è¯æ·»åŠ åï¼Œå¯é€‰æ‹©å¤šç§å¯¼å‡ºæ ¼å¼ï¼š\n   - CSVï¼šé€‚åˆå¯¼å…¥Excelæˆ–å…¶ä»–å·¥å…·\n   - JSONï¼šç”¨äºå¤‡ä»½æˆ–åç»­å¯¼å…¥\n   - APKGï¼šå¯ç›´æ¥å¯¼å…¥Ankiçš„å¡ç»„æ–‡ä»¶\n   - Markdownï¼šé€‚åˆé˜…è¯»å’Œåˆ†äº«\n\n2. å¯¼å‡ºæ–‡ä»¶ä¼šä¿å­˜åœ¨exportsæ–‡ä»¶å¤¹ä¸­"
    },
    {
        "title": "è‰ç¨¿åŠŸèƒ½",
        "content": "1.ç¨‹åºä¼šæ¯5ç§’è‡ªåŠ¨ä¿å­˜å½“å‰å•è¯åˆ—è¡¨\n\n2.å¯ç‚¹å‡»ã€ŒğŸ§¾ æš‚å­˜è‰ç¨¿ã€æ‰‹åŠ¨ä¿å­˜\n\n3.ç‚¹å‡»ã€ŒğŸ“‚ å¯¼å…¥è‰ç¨¿ã€å¯åŠ è½½ä¹‹å‰ä¿å­˜çš„JSONæ–‡ä»¶\n\n4. å…³é—­ç¨‹åºæ—¶ä¼šè‡ªåŠ¨ä¿å­˜å½“å‰å†…å®¹"
    }
]


vocab_model = genanki.Model(
    1607392319,
    'Vocabulary Model',
    fields=[
        {'name': 'Word'},
        {'name': 'Phonetic'},
        {'name': 'PartOfSpeech'},
        {'name': 'Meaning'},
        {'name': 'Mnemonic'},
    ],
    templates=[
        {
            'name': 'Card 1',
            'qfmt': '''
            <div class="word">{{Word}}</div>
            <div class="phonetic">{{Phonetic}}</div>
            <div class="pos">{{PartOfSpeech}}</div>
            ''',
            'afmt': '''
            {{FrontSide}}
            <div class="meaning">{{Meaning}}</div>
            <div class="mnemonic">{{Mnemonic}}</div>
            ''',
        },
    ],
    css='''
    .card{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial; font-size:20px; text-align:center; padding:14px; }
    .word{ font-weight:bold; font-size:32px; color:#111; }
    .phonetic{ font-style:italic; color:#666; margin-top:6px; font-size:18px; }
    .pos{ margin-top:6px; color:#444; font-size:18px; }
    .meaning{ margin-top:12px; font-size:20px; color:#1a7f1a; }
    .mnemonic{ margin-top:8px; font-size:16px; color:#6b4fbf; }
    '''
)



# ---------------- Utility Functions ----------------
def contains_cjk(s):
    return bool(s and CJK_RE.search(s))

#---------æå–æ–‡ä»¶çš„è¯æ±‡-------------
# ä» 1.py ç§»æ¤çš„è¯æ€§æ˜ å°„å’Œè¯å½¢è¿˜åŸå‡½æ•°
def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    mapping = {'J': wordnet.ADJ, 'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV}
    return mapping.get(tag, wordnet.NOUN)

def lemmatize_word(word, lemmatizer):
    return lemmatizer.lemmatize(word.lower(), get_wordnet_pos(word))

# å¤„ç† MD æ–‡ä»¶çš„å‡½æ•°ï¼ˆä¿®æ”¹ä¸ºè¿”å›è¿‡æ»¤åçš„å•è¯åˆ—è¡¨ï¼Œé€‚åº” Anki_Maker çš„ UIï¼‰
def process_md_file(md_file):
    lemmatizer = WordNetLemmatizer()
    try:
        with open(md_file, "r", encoding="utf-8") as f:
            text = f.read()
    except Exception as e:
        return None, f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{str(e)}"

    # æå–è‹±æ–‡å•è¯å¹¶è¯å½¢è¿˜åŸ
    words = re.findall(r"[a-zA-Z']+", text)
    lemmatized = set(lemmatize_word(w, lemmatizer) for w in words)

    # è¯»å–åœç”¨è¯
    script_dir = os.path.dirname(os.path.abspath(__file__))
    oxford_file = os.path.join(script_dir, "stopwords.txt")
    if not os.path.exists(oxford_file):
        return None, f"æ‰¾ä¸åˆ° stopwords.txt æ–‡ä»¶\nè·¯å¾„ï¼š{oxford_file}"

    with open(oxford_file, "r", encoding="utf-8") as f:
        oxford_words = set(line.strip().lower() for line in f)

    # è¿‡æ»¤åœç”¨è¯
    extra_stopwords = {"ve", "ll", "d", "m", "re", "s", "t", "isn", "wouldn"}
    filtered = sorted(lemmatized - oxford_words - extra_stopwords)
    return filtered, None

def detect_file_encoding(file_path):
    """æ£€æµ‹æ–‡ä»¶ç¼–ç æ ¼å¼"""
    with open(file_path, 'rb') as f:
        # è¯»å–å‰10000å­—èŠ‚ç”¨äºæ£€æµ‹ï¼ˆå¹³è¡¡å‡†ç¡®æ€§å’Œæ€§èƒ½ï¼‰
        raw_data = f.read(10000)
    
    result = chardet.detect(raw_data)
    encoding = result['encoding']
    confidence = result['confidence']
    
    # å¤„ç†æ£€æµ‹å¤±è´¥çš„æƒ…å†µï¼Œæä¾›å¸¸è§å¤‡é€‰ç¼–ç 
    if not encoding or confidence < 0.7:
        return ['utf-8', 'gbk', 'gb2312', 'utf-16', 'latin-1']
    return [encoding, 'utf-8', 'gbk']  # ä¼˜å…ˆä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç ï¼Œå†å°è¯•å¤‡é€‰

def process_txt_file(txt_file):
    """å¤„ç†TXTæ–‡ä»¶å¹¶è¿”å›è¿‡æ»¤åçš„å•è¯åˆ—è¡¨ï¼ˆå¢å¼ºç¼–ç æ”¯æŒï¼‰"""
    lemmatizer = WordNetLemmatizer()
    text = None
    
    # æ£€æµ‹æ–‡ä»¶ç¼–ç å¹¶å°è¯•å¤šç§ç¼–ç è¯»å–
    encodings = detect_file_encoding(txt_file)
    for encoding in encodings:
        try:
            with open(txt_file, "r", encoding=encoding) as f:
                text = f.read()
            break  # è¯»å–æˆåŠŸåˆ™é€€å‡ºç¼–ç å°è¯•
        except UnicodeDecodeError:
            continue  # å°è¯•ä¸‹ä¸€ç§ç¼–ç 
        except Exception as e:
            return None, f"è¯»å–TXTæ–‡ä»¶å¤±è´¥ï¼š{str(e)}"
    
    if text is None:
        return None, (
            "æ— æ³•è¯»å–æ–‡ä»¶ï¼Œå¯èƒ½åŸå› ï¼š\n"
            "1. æ–‡ä»¶ç¼–ç æ ¼å¼ä¸è¯†åˆ«\n"
            "2. æ–‡ä»¶æŸåæˆ–ä¸æ˜¯æ–‡æœ¬æ–‡ä»¶"
        )
    
    # æå–è‹±æ–‡å•è¯å¹¶è¯å½¢è¿˜åŸï¼ˆåç»­é€»è¾‘ä¸å˜ï¼‰
    words = re.findall(r"[a-zA-Z']+", text)
    lemmatized = set(lemmatize_word(w, lemmatizer) for w in words)
    return filter_stopwords(lemmatized)

def process_pdf_file(pdf_file):
    """å¤„ç†PDFæ–‡ä»¶å¹¶è¿”å›è¿‡æ»¤åçš„å•è¯åˆ—è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    lemmatizer = WordNetLemmatizer()
    text = ""
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(pdf_file):
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if os.path.getsize(pdf_file) == 0:
        return None, "PDFæ–‡ä»¶ä¸ºç©º"
    
    # å°è¯•å¤šç§PDFæå–æ–¹æ¡ˆ
    extraction_methods = [
        ("PyPDF2", extract_with_pypdf2),
        ("textract", extract_with_textract),
        ("pdfplumber", extract_with_pdfplumber)  # å¢åŠ pdfplumberä½œä¸ºå¤‡é€‰
    ]
    
    for method_name, extract_func in extraction_methods:
        try:
            text = extract_func(pdf_file)
            if text and len(text.strip()) > 0:
                break  # æå–æˆåŠŸåˆ™åœæ­¢å°è¯•å…¶ä»–æ–¹æ³•
        except Exception as e:
            print(f"ä½¿ç”¨{method_name}æå–å¤±è´¥: {str(e)}")  # ä»…åœ¨æ§åˆ¶å°æ‰“å°ï¼Œä¸ä¸­æ–­
    
    if not text or len(text.strip()) == 0:
        return None, (
            "æ— æ³•ä»PDFä¸­æå–æ–‡æœ¬å†…å®¹ã€‚å¯èƒ½åŸå› ï¼š\n"
            "1. PDFæ˜¯æ‰«æä»¶ï¼ˆå›¾ç‰‡æ ¼å¼ï¼‰\n"
            "2. PDFè¢«åŠ å¯†ä¿æŠ¤\n"
            "3. æ ¼å¼æŸåæˆ–ä¸è§„èŒƒ"
        )
    
    # æå–è‹±æ–‡å•è¯å¹¶è¯å½¢è¿˜åŸ
    words = re.findall(r"[a-zA-Z']+", text)
    lemmatized = set(lemmatize_word(w, lemmatizer) for w in words)
    
    # è¿‡æ»¤åœç”¨è¯
    return filter_stopwords(lemmatized)

# è¾…åŠ©æå–å‡½æ•°
def extract_with_pypdf2(pdf_file):
    """ä½¿ç”¨PyPDF2æå–æ–‡æœ¬"""
    text = ""
    with open(pdf_file, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        # æ£€æŸ¥æ˜¯å¦åŠ å¯†
        if reader.is_encrypted:
            try:
                # å°è¯•ç©ºå¯†ç è§£å¯†ï¼ˆéƒ¨åˆ†PDFä»…é™åˆ¶ç¼–è¾‘ï¼Œä¸é™åˆ¶é˜…è¯»ï¼‰
                reader.decrypt("")
            except Exception:
                raise Exception("PDFå·²åŠ å¯†ï¼Œéœ€è¦å¯†ç æ‰èƒ½æå–å†…å®¹")
        
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def extract_with_textract(pdf_file):
    """ä½¿ç”¨textractæå–æ–‡æœ¬ï¼ˆå¢å¼ºç¼–ç å®¹é”™ï¼‰"""
    try:
        # å…ˆå°è¯•é»˜è®¤ç¼–ç 
        raw_data = textract.process(pdf_file)
        return raw_data.decode('utf-8', errors='replace')  # æ— æ³•è§£ç çš„å­—ç¬¦ç”¨ï¿½æ›¿ä»£
    except UnicodeDecodeError:
        # å°è¯•GBKç¼–ç 
        try:
            return raw_data.decode('gbk', errors='replace')
        except:
            # æœ€åå°è¯•latin-1ï¼ˆå‡ ä¹èƒ½è§£ç æ‰€æœ‰å­—èŠ‚ï¼Œä½†å¯èƒ½ä¹±ç ï¼‰
            return raw_data.decode('latin-1')
def extract_with_pdfplumber(pdf_file):
    """ä½¿ç”¨pdfplumberæå–æ–‡æœ¬ï¼ˆéœ€è¦é¢å¤–å®‰è£…pdfplumberï¼‰"""
    text = ""
    try:
        import pdfplumber  # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æœªå®‰è£…æ—¶å‡ºé”™
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    except ImportError:
        raise Exception("pdfplumberæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨æ­¤æå–æ–¹æ³•")
    except Exception as e:
        raise Exception(f"pdfplumberæå–å¤±è´¥: {str(e)}")
def process_word_file(word_file):
    """å¤„ç†Wordæ–‡ä»¶(.docx)å¹¶è¿”å›è¿‡æ»¤åçš„å•è¯åˆ—è¡¨ï¼ˆå¢å¼ºç¼–ç æ”¯æŒï¼‰"""
    lemmatizer = WordNetLemmatizer()
    try:
        raw_data = textract.process(word_file)
        # å°è¯•å¤šç§ç¼–ç è§£ç 
        encodings = ['utf-8', 'gbk', 'gb2312']
        text = None
        for encoding in encodings:
            try:
                text = raw_data.decode(encoding, errors='ignore')
                if text.strip():  # ç¡®ä¿è§£ç ç»“æœéç©º
                    break
            except:
                continue
        if not text:
            return None, "æ— æ³•è§£ç Wordæ–‡æ¡£å†…å®¹"
    except Exception as e:
        return None, f"è¯»å–Wordæ–‡ä»¶å¤±è´¥ï¼š{str(e)}"
    
    # åç»­å¤„ç†é€»è¾‘ä¸å˜
    words = re.findall(r"[a-zA-Z']+", text)
    lemmatized = set(lemmatize_word(w, lemmatizer) for w in words)
    return filter_stopwords(lemmatized)


def filter_stopwords(word_set):
    """è¿‡æ»¤åœç”¨è¯å¹¶è¿”å›å¤„ç†ç»“æœ"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    oxford_file = os.path.join(script_dir, "stopwords.txt")
    
    if not os.path.exists(oxford_file):
        return None, f"æ‰¾ä¸åˆ° stopwords.txt æ–‡ä»¶\nè·¯å¾„ï¼š{oxford_file}"
    
    with open(oxford_file, "r", encoding="utf-8") as f:
        oxford_words = set(line.strip().lower() for line in f)
    
    # è¿‡æ»¤åœç”¨è¯
    extra_stopwords = {"ve", "ll", "d", "m", "re", "s", "t", "isn", "wouldn"}
    filtered = sorted(word_set - oxford_words - extra_stopwords)
    return filtered, None


def detect_pos_from_defs(defs):
    if not defs:
        return ""

    for d in defs:
        if not d:
            continue
        m = POS_PREFIX_RE.match(d)
        if m:
            return m.group(1)

    for d in defs:
        low = d.lower()
        for tag in ("noun", "verb", "adj", "adv", "prep", "conj", "pron", "det"):
            if low.startswith(tag) or f" {tag} " in low:
                return tag

    return ""


def extract_chinese_translations(defs):
    if not defs:
        return []
    return [d.strip() for d in defs if d and contains_cjk(d)]


def open_folder(path):
    try:
        if sys.platform == "darwin":
            subprocess.call(["open", path])
        elif sys.platform.startswith("win"):
            subprocess.call(["explorer", path])
        else:
            subprocess.call(["xdg-open", path])
    except Exception:
        pass


def ensure_export_folder():
    os.makedirs(EXPORT_FOLDER, exist_ok=True)

#=========æ•™ç¨‹çš„çª—å£===========
class TutorialWindow(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.parent = parent
        self.title("Anki Maker ä½¿ç”¨æ•™ç¨‹")
        self.geometry("600x400")
        self.current_page = 0
        self.total_pages = len(TUTORIAL_CONTENTS)
        
        # ç¡®ä¿çª—å£åœ¨çˆ¶çª—å£ä¸­å¤®
        self.transient(parent)
        self.grab_set()
        
        self._create_widgets()
        self._update_content()
        nltk.download('punkt', quiet=True)
        nltk.download('averaged_perceptron_tagger', quiet=True)
        nltk.download('wordnet', quiet=True)
            # å‰ªè´´æ¿ç›‘å¬ç›¸å…³
        self.clipboard_listening = False
        self.last_clipboard_content = ""
        self.clipboard_thread = None
        self.stop_clipboard_event = threading.Event()  # ç”¨äºä¼˜é›…åœæ­¢çº¿ç¨‹

    def _create_widgets(self):
        # æ ‡é¢˜æ ‡ç­¾
        self.title_label = ttk.Label(
            self, 
            text="", 
            font=("Arial", 30, "bold")
        )
        self.title_label.pack(pady=(15, 10), padx=20, anchor="w")
        
        # å†…å®¹æ–‡æœ¬æ¡†
        self.content_text = tk.Text(
            self, 
            wrap=tk.WORD, 
            width=70, 
            height=12,
            font=("Arial", 20),
            relief=tk.FLAT,
            bg=self.cget("bg")
        )
        self.content_text.pack(padx=20, fill="both", expand=True)
        self.content_text.config(state=tk.DISABLED)
        
        # å¯¼èˆªæŒ‰é’®åŒºåŸŸ
        nav_frame = ttk.Frame(self)
        nav_frame.pack(pady=15, fill="x", padx=20)
        
        self.prev_btn = ttk.Button(
            nav_frame, 
            text="ä¸Šä¸€é¡µ", 
            command=self.prev_page
        )
        self.prev_btn.pack(side="left")
        
        self.page_label = ttk.Label(nav_frame, text="")
        self.page_label.pack(side="left", padx=20, expand=True)
        
        self.next_btn = ttk.Button(
            nav_frame, 
            text="ä¸‹ä¸€é¡µ", 
            command=self.next_page
        )
        self.next_btn.pack(side="right")
        
        self.close_btn = ttk.Button(
            nav_frame, 
            text="å…³é—­", 
            command=self.destroy
        )
        self.close_btn.pack(side="right", padx=10)
        
    def _update_content(self):
        # æ›´æ–°å½“å‰é¡µå†…å®¹
        page = TUTORIAL_CONTENTS[self.current_page]
        self.title_label.config(text=page["title"])
        
        self.content_text.config(state=tk.NORMAL)
        self.content_text.delete("1.0", tk.END)
        self.content_text.insert("1.0", page["content"])
        self.content_text.config(state=tk.DISABLED)
        
        # æ›´æ–°é¡µç æ˜¾ç¤º
        self.page_label.config(text=f"{self.current_page + 1}/{self.total_pages}")
        
        # æ§åˆ¶æŒ‰é’®çŠ¶æ€
        self.prev_btn.config(state=tk.NORMAL if self.current_page > 0 else tk.DISABLED)
        self.next_btn.config(state=tk.NORMAL if self.current_page < self.total_pages - 1 else tk.DISABLED)
        
    def prev_page(self):
        if self.current_page > 0:
            self.current_page -= 1
            self._update_content()
            
    def next_page(self):
        if self.current_page < self.total_pages - 1:
            self.current_page += 1
            self._update_content()






# ---------------- DictLookup ----------------
class DictLookup:
    def __init__(self, json_path=None):
        self.words = []  # å­˜å‚¨æ‰€æœ‰å•è¯
        self.path = json_path or DEFAULT_DICT
        self.data = {}
        self.load(self.path)

    def load(self, path):
        self.path = path
        self.data = {}
        if not path or not os.path.exists(path):
            return
        try:
            with open(path, "r", encoding="utf-8") as f:
                raw = json.load(f)
            for k, v in raw.items():
                if k:
                    self.data[k.strip().lower()] = v
        except Exception:
            self.data = {}

    def lookup(self, word):
        if not word:
            return None

        key = word.strip().lower()
        if key in self.data:
            return self._to_result(key, self.data[key])

        alt = key.strip("'\"")
        if alt in self.data:
            return self._to_result(alt, self.data[alt])

        for k in self.data:
            if k.endswith(key):
                return self._to_result(k, self.data[k])

        return None

    def _to_result(self, key, entry):
        phonetic = entry.get("phonetic", "") or ""
        defs = entry.get("definitions", []) or []
        pos = detect_pos_from_defs(defs)
        translations = extract_chinese_translations(defs)
        return {
            "word": key,
            "phonetic": phonetic,
            "pos": pos,
            "translations": translations,
            "definitions": defs,
            "exchange": entry.get("exchange", {}) or {}
        }


# ---------------- Main App ----------------
class AnkiMakerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Anki Maker Version 3.0")
        self.data = []
        self.clipboard_listening = False  # ç›‘å¬çŠ¶æ€
        self.last_clipboard_content = ""  # ä¸Šæ¬¡å‰ªè´´æ¿å†…å®¹ç¼“å­˜
        self.dict_lookup = DictLookup()
        self.autosave_running = True
        self._build_ui()
        self._load_draft()
        self._start_autosave()

        # load local dict.json
        # åˆå§‹åŒ–ç©ºè¯å…¸ï¼Œåç»­é€šè¿‡çº¿ç¨‹åŠ è½½
        self.dict_lookup = DictLookup()  # å…ˆåˆå§‹åŒ–ç©ºè¯å…¸
        self.default_dict_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), DEFAULT_DICT)
        self.status("ç¨‹åºå¯åŠ¨ä¸­...")
        # å»¶è¿Ÿ0.5ç§’å†å¯åŠ¨è¯å…¸åŠ è½½çº¿ç¨‹ï¼Œä¼˜å…ˆä¿è¯çª—å£æ˜¾ç¤º
        self.root.after(500, lambda: threading.Thread(
            target=self._load_dict_in_background, daemon=True
        ).start())

    def _check_and_load_default_dict(self):
        """æ£€æŸ¥å¹¶åŠ è½½é»˜è®¤è¯å…¸"""
        if os.path.exists(self.default_dict_path):
            self.dict_lookup.load(self.default_dict_path)
            self.status(f"å·²åŠ è½½é»˜è®¤è¯å…¸ï¼Œå…± {len(self.dict_lookup.data)} ä¸ªè¯æ¡")
        else:
            self.status(f"æœªæ‰¾åˆ°é»˜è®¤è¯å…¸: {self.default_dict_path}")

    def check_first_run(self):
        if not os.path.exists("first_run_flag"):
            with open("first_run_flag", "w") as f:
                f.write("1")
            self.show_tutorial()

    # ---------------- UI Construction ----------------
    def _build_ui(self):
        frm = ttk.Frame(self.root, padding=10)
        frm.pack(fill="both", expand=True)
        row = 0

        # Input fields
        ttk.Label(frm, text="Word").grid(row=row, column=0, sticky="e")
        self.word_entry = ttk.Entry(frm, width=40)
        self.word_entry.grid(row=row, column=1, sticky="w")
        self.word_entry.focus_set()

        row += 1
        ttk.Label(frm, text="éŸ³æ ‡").grid(row=row, column=0, sticky="e")
        self.phonetic_entry = ttk.Entry(frm, width=40)
        self.phonetic_entry.grid(row=row, column=1, sticky="w")

        row += 1
        ttk.Label(frm, text="è¯æ€§").grid(row=row, column=0, sticky="e")
        self.pos_entry = ttk.Entry(frm, width=40)
        self.pos_entry.grid(row=row, column=1, sticky="w")

        row += 1
        ttk.Label(frm, text="é‡Šä¹‰").grid(row=row, column=0, sticky="ne")
        self.definition_text = tk.Text(frm, width=50, height=4)
        self.definition_text.grid(row=row, column=1, sticky="w")

        row += 1
        ttk.Label(frm, text="åŠ©è®°").grid(row=row, column=0, sticky="ne")
        self.example_text = tk.Text(frm, width=50, height=3)
        self.example_text.grid(row=row, column=1, sticky="w")

        # Search box
        row += 1
        ttk.Label(frm, text="æœç´¢:").grid(row=row, column=0, sticky="e")
        self.search_var = tk.StringVar()
        search_entry = ttk.Entry(frm, textvariable=self.search_var)
        search_entry.grid(row=row, column=1, sticky="we")
        search_entry.bind("<KeyRelease>", self.filter_tree)

        # Buttons
        row += 1
        btn_frame = ttk.Frame(frm)
        btn_frame.grid(row=row, column=1, sticky="w", pady=(8, 0))
        # æ›¿æ¢åŸæ¥çš„æŒ‰é’®åˆ›å»ºä»£ç 
        def create_extra_buttons():
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º CSV", command=self.export_csv).grid(row=1, column=0, padx=6)
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º JSON", command=self.export_json).grid(row=1, column=1, padx=6)
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º APKG", command=self.export_apkg).grid(row=1, column=2, padx=6)
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º MD", command=self.export_md).grid(row=1, column=3, padx=6)
            ttk.Button(btn_frame, text="ğŸ—‘ åˆ é™¤é€‰ä¸­", command=self.delete_selected_item).grid(row=2, column=0, padx=6)
            ttk.Button(btn_frame, text="ğŸ§¹ æ¸…ç©ºæ‰€æœ‰", command=self.clear_all_items).grid(row=2, column=2, padx=6)
            ttk.Button(btn_frame, text="ğŸ“‹ å¼€å§‹/ç»“æŸç›‘å¬å‰ªè´´æ¿", command=self.toggle_clipboard_listen).grid(row=3, column=2, padx=6)
            ttk.Button(btn_frame, text="ğŸ“– ä½¿ç”¨æ•™ç¨‹", command=self.show_tutorial).grid(row=2, column=1, padx=6)
            ttk.Button(btn_frame, text="ğŸ“‚ å¯¼å…¥è¯å…¸(è®°å¾—å…ˆæŠŠzipè§£å‹)", command=self.load_dict_file).grid(row=2, column=3, padx=6)
            ttk.Button(btn_frame, text="ğŸ“„ æ‰¹é‡å¯¼å…¥ TXT", command=self.import_txt_file).grid(row=3, column=0, padx=6)
            ttk.Button(btn_frame, text="ğŸ“„ ä»MD/PDF/WORD/TXTæå–å•è¯", command=self.select_md_file).grid(row=3, column=1, padx=6)

        # ä¸»æŒ‰é’®å…ˆåˆ›å»º
        ttk.Button(btn_frame, text="â• æ·»åŠ è¯æ¡", command=self.add_word).grid(row=0, column=0, padx=6)
        ttk.Button(btn_frame, text="ğŸ§¾ æš‚å­˜è‰ç¨¿", command=self.save_draft).grid(row=0, column=1, padx=6)
        ttk.Button(btn_frame, text="ğŸ“‚ å¯¼å…¥è‰ç¨¿", command=self.import_json_draft).grid(row=0, column=2, padx=6)
        ttk.Button(btn_frame, text="ğŸ” è‡ªåŠ¨è¡¥å…¨ (Cmd/Ctrl+E)", command=self.autofill_from_dict).grid(row=0, column=3, padx=6)

        # å»¶è¿Ÿåˆ›å»ºå…¶ä»–æŒ‰é’®
        self.root.after(300, create_extra_buttons)
        # Treeview for added words
        row += 1
        list_frame = ttk.LabelFrame(frm, text="å·²æ·»åŠ è¯æ¡", padding=(6, 6))
        list_frame.grid(row=row, column=0, columnspan=2, pady=(10, 0), sticky="nsew")
        frm.rowconfigure(row, weight=1)
        frm.columnconfigure(1, weight=1)

        columns = ("word", "phonetic", "pos", "definition")
        self.tree = ttk.Treeview(list_frame, columns=columns, show="headings", height=12)
        for c in columns:
            self.tree.heading(c, text=c)
        self.tree.column("word", width=150)
        self.tree.column("phonetic", width=120)
        self.tree.column("pos", width=80)
        self.tree.column("definition", width=360)
        self.tree.pack(side="left", fill="both", expand=True)

        sb = ttk.Scrollbar(list_frame, orient="vertical", command=self.tree.yview)
        sb.pack(side="right", fill="y")
        self.tree.configure(yscrollcommand=sb.set)
        self.tree.bind("<Double-1>", self.on_tree_double)

        # Status bar
        self.status_var = tk.StringVar(value="Ready")
        ttk.Label(self.root, textvariable=self.status_var, relief="sunken", anchor="w").pack(side="bottom", fill="x")

        # Key bindings
        self.word_entry.bind("<Return>", lambda e: self.pos_entry.focus_set())
        self.pos_entry.bind("<Return>", lambda e: self.definition_text.focus_set())
        self.definition_text.bind("<Return>", lambda e: self.example_text.focus_set())
        self.example_text.bind("<Return>", lambda e: self.add_word())
        self.root.bind_all("<Control-e>", lambda e: self.autofill_from_dict())
        self.root.bind_all("<Command-e>", lambda e: self.autofill_from_dict())
        self.root.bind_all("<Control-s>", lambda e: self.save_draft())
        self.root.bind_all("<Command-s>", lambda e: self.save_draft())
        self.root.protocol("WM_DELETE_WINDOW", self.on_close)
        self.root.bind("<Control-Return>", lambda e: self.add_word())  # Windows/Linux
        self.root.bind("<Command-Return>", lambda e: self.add_word())   # macOS
        self.definition_text.bind("<Control-Return>", self.handle_definition_newline)  # Windows/Linux
        self.definition_text.bind("<Command-Return>", self.handle_definition_newline)   # macOS

        # try auto-load dict.json
        script_dir = os.path.dirname(os.path.abspath(__file__))
        default_path = os.path.join(script_dir, DEFAULT_DICT)
        if os.path.exists(default_path):
            self.dict_lookup.load(default_path)
        # åœ¨ _build_ui æ–¹æ³•æœ«å°¾ï¼Œç°æœ‰ç»‘å®šè¯­å¥åé¢æ·»åŠ ï¼š
        self.tree.bind("<Delete>", self.delete_selected_item)
        # åŠ©è®°æ¡†ï¼šæŒ‰ Command+Enter/Ctrl+Enter æ¢è¡Œï¼Œæ™®é€š Enter è§¦å‘æ·»åŠ è¯æ¡
        self.example_text.bind("<Control-Return>", self.handle_example_newline)  # Windows
        self.example_text.bind("<Command-Return>", self.handle_example_newline)   # macOS
        self.example_text.bind("<Return>", lambda e: self.add_word())  # æ™®é€šEnteræ·»åŠ è¯æ¡
        # å…ˆæ˜¾ç¤ºä¸»çª—å£
        self.root.update_idletasks()
        self.root.deiconify()

        # å»¶è¿Ÿåˆ›å»ºå¯¼å‡ºæŒ‰é’®ç­‰éæ ¸å¿ƒç»„ä»¶
        def create_extra_buttons():
            # è¿™é‡Œæ”¾åŸæ¥çš„å¯¼å‡ºæŒ‰é’®ã€ç›‘å¬æŒ‰é’®ç­‰ä»£ç 
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º CSV", command=self.export_csv).grid(row=1, column=0, padx=6)
            ttk.Button(btn_frame, text="ğŸ“¤ å¯¼å‡º JSON", command=self.export_json).grid(row=1, column=1, padx=6)
            # ... å…¶ä»–æŒ‰é’® ...

        # æ›¿æ¢åŸæ¥çš„æŒ‰é’®åˆ›å»ºä»£ç ï¼Œæ”¹ä¸ºå»¶è¿Ÿåˆ›å»º

    # ---------------- UI Helpers ----------------
    def status(self, txt):
        """å®‰å…¨åœ°æ›´æ–°çŠ¶æ€æ ï¼ˆç¡®ä¿åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼‰"""
        def update_status():
            self.status_var.set(txt)
        # ä½¿ç”¨afterå°†æ“ä½œæäº¤åˆ°ä¸»çº¿ç¨‹
        self.root.after(0, update_status)
    def clear_inputs(self):
        self.word_entry.delete(0, tk.END)
        self.phonetic_entry.delete(0, tk.END)
        self.pos_entry.delete(0, tk.END)
        self.definition_text.delete("1.0", tk.END)
        self.example_text.delete("1.0", tk.END)
        self.word_entry.focus_set()

    # ---------------- Dictionary Functions ----------------
    def load_dict_file(self):
        p = filedialog.askopenfilename(title="é€‰æ‹©è¯å…¸æ–‡ä»¶",
                                    filetypes=[("JSON", "*.json"), ("All files", "*.*")])
        if p:
            self.dict_lookup.load(p)
            self.status(f"å·²åŠ è½½è¯å…¸ï¼š{p}ï¼Œå…± {len(self.dict_lookup.data)} ä¸ªè¯æ¡")
                
    def refresh_treeview(self):
        """åˆ·æ–°æ ‘çŠ¶è§†å›¾ï¼Œæ˜¾ç¤ºæœ€æ–°çš„å•è¯åˆ—è¡¨"""
        # å…ˆæ¸…ç©ºç°æœ‰å†…å®¹
        self.tree.delete(*self.tree.get_children())
        # é‡æ–°æ·»åŠ æ‰€æœ‰æ•°æ®
        for item in self.data:
            self._tree_insert(item)


    def autofill_from_dict(self):
        """ä»è¯å…¸è‡ªåŠ¨å¡«å……å•è¯çš„éŸ³æ ‡ã€è¯æ€§å’Œé‡Šä¹‰"""
        word = self.word_entry.get().strip()
        if not word:
            self.status("è¯·å…ˆè¾“å…¥å•è¯")
            return

        # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
        self.status(f"æ­£åœ¨æŸ¥è¯¢ {word} çš„ä¿¡æ¯...")
        
        # ä»è¯å…¸æŸ¥è¯¢å•è¯
        result = self.dict_lookup.lookup(word)
        if not result:
            self.status(f"æœªåœ¨è¯å…¸ä¸­æ‰¾åˆ° {word} çš„ä¿¡æ¯")
            return

        # å¡«å……éŸ³æ ‡ï¼ˆä¿®å¤å˜é‡åæ‹¼å†™é”™è¯¯ï¼šphon â†’ phoneticï¼‰
        phonetic = result.get("phonetic", "")
        if phonetic:
            self.phonetic_entry.delete(0, tk.END)
            self.phonetic_entry.insert(0, phonetic)

        # å¡«å……è¯æ€§
        pos = result.get("pos", "")
        if pos:
            self.pos_entry.delete(0, tk.END)
            self.pos_entry.insert(0, pos)

        # å¡«å……é‡Šä¹‰
        translations = result.get("translations", [])
        if translations:
            self.definition_text.delete("1.0", tk.END)
            self.definition_text.insert("1.0", "\n".join(translations))

        # è‡ªåŠ¨èšç„¦åˆ°åŠ©è®°æ¡†ï¼Œæ–¹ä¾¿ç”¨æˆ·è¾“å…¥
        self.example_text.focus_set()
        
        self.status(f"å·²è‡ªåŠ¨è¡¥å…¨ {word} çš„ä¿¡æ¯")


    # æ·»åŠ å‰ªè´´æ¿ç›‘å¬æ§åˆ¶æ–¹æ³•
    def toggle_clipboard_listening(self):
        """åˆ‡æ¢å‰ªè´´æ¿ç›‘å¬çŠ¶æ€"""
        if self.clipboard_listening:
            # åœæ­¢ç›‘å¬
            self.clipboard_listening = False
            self.stop_clipboard_event.set()
            self.status("å·²åœæ­¢ç›‘å¬å‰ªè´´æ¿")
            self.clipboard_btn.config(text="ğŸ“‹ å¼€å§‹ç›‘å¬å‰ªè´´æ¿")
        else:
            # å¼€å§‹ç›‘å¬
            self.clipboard_listening = True
            self.stop_clipboard_event.clear()
            self.clipboard_thread = threading.Thread(
                target=self._clipboard_listener,
                daemon=True
            )
            self.clipboard_thread.start()
            self.status("å·²å¼€å§‹ç›‘å¬å‰ªè´´æ¿...")
            self.clipboard_btn.config(text="ğŸ“‹ åœæ­¢ç›‘å¬å‰ªè´´æ¿")

    # æ·»åŠ æ ¸å¿ƒç›‘å¬é€»è¾‘
    def _clipboard_listener(self):
        """å‰ªè´´æ¿ç›‘å¬çº¿ç¨‹"""
        while self.clipboard_listening and not self.stop_clipboard_event.is_set():
            try:
                # è·å–å‰ªè´´æ¿å†…å®¹
                current_content = self.root.clipboard_get().strip()
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦å˜åŒ–ä¸”æ˜¯å•ä¸ªè‹±æ–‡å•è¯
                if (current_content and 
                    current_content != self.last_clipboard_content and 
                    self._is_single_english_word(current_content)):
                    
                    self.last_clipboard_content = current_content
                    self._process_clipboard_word(current_content)
                    
            except Exception as e:
                # å¿½ç•¥å‰ªè´´æ¿è®¿é—®é”™è¯¯ï¼ˆå¦‚æ— å†…å®¹æ—¶ï¼‰
                pass
                
            # çŸ­æš‚ä¼‘çœ å‡å°‘CPUå ç”¨
            time.sleep(0.5)

    # æ·»åŠ è¾…åŠ©æ–¹æ³•
    def _is_single_english_word(self, text):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå•ä¸ªè‹±æ–‡å•è¯"""
        # ä»…åŒ…å«å­—æ¯å’Œå¯èƒ½çš„æ’‡å·ï¼ˆå¦‚don'tï¼‰
        return bool(re.fullmatch(r"[a-zA-Z']+", text))

    def _process_clipboard_word(self, word):
        """å¤„ç†å‰ªè´´æ¿è·å–çš„å•è¯"""
        # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
        self.root.after(0, lambda: self._handle_clipboard_word_ui(word))
        
        # å‘é€ç³»ç»Ÿé€šçŸ¥
        try:
            notification_title = "Anki Maker"
            notification_message = f"å·²æ•è·å•è¯: {word}"
            notification.notify(
                title=notification_title,
                message=notification_message,
                timeout=2
            )
            
            # MacOSé¢å¤–çš„AppleScripté€šçŸ¥ï¼ˆæ›´ä¼˜é›…ï¼‰
            if sys.platform == "darwin":
                applescript = f'''
                display notification "{notification_message}" with title "{notification_title}" sound name "default"
                '''
                subprocess.run(["osascript", "-e", applescript])
        except Exception:
            pass

    def _handle_clipboard_word_ui(self, word):
        """åœ¨UIçº¿ç¨‹ä¸­å¤„ç†å•è¯ï¼ˆè‡ªåŠ¨è¡¥å…¨å¹¶æ·»åŠ ï¼‰"""
        # å¡«å……å•è¯è¾“å…¥æ¡†
        self.word_entry.delete(0, tk.END)
        self.word_entry.insert(0, word)
        
        # è‡ªåŠ¨è¡¥å…¨å•è¯ä¿¡æ¯
        self.auto_complete()
        
        # è‡ªåŠ¨æ·»åŠ åˆ°åˆ—è¡¨
        self.add_entry()



                    # ---------------- Add / Edit ----------------
    def add_word(self, is_auto=False, skip_validation=False):  # å¢åŠ skip_validationå‚æ•°
        word = self.word_entry.get().strip()
        if not word:
            return

        phon = self.phonetic_entry.get().strip()

        if not phon:
            res = self.dict_lookup.lookup(word)
            if res and res.get("phonetic"):
                phon = res["phonetic"]

        pos = self.pos_entry.get().strip()
        definition = self.definition_text.get("1.0", tk.END).strip()
        example = self.example_text.get("1.0", tk.END).strip()

        # åªæœ‰éè·³è¿‡éªŒè¯æ¨¡å¼ä¸”é‡Šä¹‰ä¸ºç©ºæ—¶æ‰æ˜¾ç¤ºè­¦å‘Š
        if not skip_validation and not definition:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "é‡Šä¹‰ä¸èƒ½ä¸ºç©º")
            return

        item = {
            "word": word,
            "phonetic": phon,
            "pos": pos,
            "definition": definition,
            "example": example
        }

        self.data.append(item)
        self._tree_insert(item)
        self.clear_inputs()
        self.status(f"å·²æ·»åŠ  {len(self.data)} æ¡è¯æ¡")

        # åªæœ‰è‡ªåŠ¨æ·»åŠ ï¼ˆå‰ªè´´æ¿ç›‘å¬ï¼‰æ—¶æ‰æ˜¾ç¤ºé€šçŸ¥
        if is_auto:
            # æ˜¾ç¤ºå•è¯å’Œé‡Šä¹‰ï¼ˆå–å‰30ä¸ªå­—ç¬¦é˜²æ­¢é€šçŸ¥è¿‡é•¿ï¼‰
            short_def = definition[:30] + "..." if len(definition) > 30 else definition
            self.show_temp_notification(f"å·²æ·»åŠ : {word}\né‡Šä¹‰: {short_def}")


    def clear_inputs(self):
        """æ¸…ç©ºæ‰€æœ‰è¾“å…¥æ¡†"""
        self.word_entry.delete(0, tk.END)
        self.phonetic_entry.delete(0, tk.END)
        self.pos_entry.delete(0, tk.END)
        self.definition_text.delete("1.0", tk.END)
        self.example_text.delete("1.0", tk.END)


    # æ”¾åœ¨ add_word / on_tree_double ä¹‹å
    def delete_selected_item(self, event=None):
        sel = self.tree.selection()
        if not sel:
            return

        indices_to_delete = [self.tree.index(item_id) for item_id in sel]
        indices_to_delete.sort(reverse=True)
        for idx in indices_to_delete:
            del self.data[idx]
        for item_id in sel:
            self.tree.delete(item_id)

        self.status(f"å·²åˆ é™¤ {len(indices_to_delete)} æ¡è¯æ¡ã€‚å‰©ä½™ {len(self.data)} æ¡ã€‚")


    def select_file_for_word_extraction(self):
        """é€‰æ‹©æ–‡ä»¶å¹¶æå–ç”Ÿè¯"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©æ–‡ä»¶æå–ç”Ÿè¯",
            filetypes=[
                ("æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶", "*.txt *.pdf *.docx *.md"),
                ("æ–‡æœ¬æ–‡ä»¶", "*.txt"),
                ("PDFæ–‡ä»¶", "*.pdf"),
                ("Wordæ–‡ä»¶", "*.docx"),
                ("Markdownæ–‡ä»¶", "*.md"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if not file_path:
            return
        
        self.status(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}...")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ç›¸åº”çš„å¤„ç†å‡½æ•°
        try:
            if file_path.endswith(".md"):
                words, error = process_md_file(file_path)
            elif file_path.endswith(".txt"):
                words, error = process_txt_file(file_path)
            elif file_path.endswith(".pdf"):
                words, error = process_pdf_file(file_path)
            elif file_path.endswith(".docx"):
                words, error = process_word_file(file_path)
            else:
                messagebox.showerror("é”™è¯¯", "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                return
                
            if error:
                messagebox.showerror("å¤„ç†å¤±è´¥", error)
                self.status("æ–‡ä»¶å¤„ç†å¤±è´¥")
                return
                
            if not words:
                messagebox.showinfo("ç»“æœ", "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç”Ÿè¯")
                self.status("æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæœªå‘ç°ç”Ÿè¯")
                return
                
            # æ˜¾ç¤ºæå–çš„ç”Ÿè¯å¹¶è¯¢é—®æ˜¯å¦æ·»åŠ 
            self.show_extracted_words(words)
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            self.status("æ–‡ä»¶å¤„ç†å‡ºé”™")

    def show_extracted_words(self, words):
        """æ˜¾ç¤ºæå–çš„ç”Ÿè¯å¹¶æä¾›æ·»åŠ é€‰é¡¹"""
        # åˆ›å»ºå¼¹çª—æ˜¾ç¤ºæå–çš„å•è¯
        dialog = tk.Toplevel(self.root)
        dialog.title(f"æå–åˆ° {len(words)} ä¸ªç”Ÿè¯")
        dialog.geometry("600x400")
        dialog.transient(self.root)
        dialog.grab_set()
        
        # æ·»åŠ æ»šåŠ¨æ–‡æœ¬æ¡†
        text = scrolledtext.ScrolledText(dialog, wrap=tk.WORD)
        text.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)
        text.insert(tk.END, "\n".join(words))
        text.config(state=tk.DISABLED)
        
        # æ·»åŠ æŒ‰é’®
        btn_frame = ttk.Frame(dialog)
        btn_frame.pack(pady=10)
        
        def add_all():
            """æ·»åŠ æ‰€æœ‰å•è¯"""
            added_count = 0
            for word in words:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥å•è¯
                exists = any(item["word"].lower() == word.lower() for item in self.data)
                if not exists:
                    # è‡ªåŠ¨å¡«å……å•è¯ä¿¡æ¯
                    self.word_entry.delete(0, tk.END)
                    self.word_entry.insert(0, word)
                    self.autofill_from_dict()
                    
                    # è·å–è‡ªåŠ¨å¡«å……çš„ä¿¡æ¯
                    phon = self.phonetic_entry.get().strip()
                    pos = self.pos_entry.get().strip()
                    definition = self.definition_text.get("1.0", tk.END).strip()
                    
                    # æ·»åŠ åˆ°åˆ—è¡¨
                    self.data.append({
                        "word": word,
                        "phonetic": phon,
                        "pos": pos,
                        "definition": definition,
                        "example": ""
                    })
                    added_count += 1
            
            self.refresh_treeview()
            self.clear_inputs()
            self.status(f"å·²æ·»åŠ  {added_count} ä¸ªç”Ÿè¯")
            dialog.destroy()
        
        ttk.Button(btn_frame, text="å…¨éƒ¨æ·»åŠ ", command=add_all).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="å–æ¶ˆ", command=dialog.destroy).pack(side=tk.LEFT, padx=5)



    def _tree_insert(self, item):
        definition = item.get("definition", "").replace("\n", " | ")
        self.tree.insert("", "end", values=(item["word"],
                                            item.get("phonetic", ""),
                                            item.get("pos", ""),
                                            definition))

    def on_tree_double(self, event):
        sel = self.tree.selection()
        if not sel:
            return

        it = sel[0]
        idx = self.tree.index(it)
        item = self.data[idx]

        self.word_entry.delete(0, tk.END)
        self.word_entry.insert(0, item["word"])

        self.phonetic_entry.delete(0, tk.END)
        self.phonetic_entry.insert(0, item.get("phonetic", ""))

        self.pos_entry.delete(0, tk.END)
        self.pos_entry.insert(0, item.get("pos", ""))

        self.definition_text.delete("1.0", tk.END)
        self.definition_text.insert("1.0", item.get("definition", ""))

        self.example_text.delete("1.0", tk.END)
        self.example_text.insert("1.0", item.get("example", ""))

        del self.data[idx]
        self.tree.delete(it)
        self.status("ç¼–è¾‘æ¨¡å¼ï¼šä¿®æ”¹åå›è½¦ æ·»åŠ è¯æ¡ ä¿å­˜æ›´æ”¹")


    def handle_definition_newline(self, event):
        """å¤„ç†é‡Šä¹‰æ¡†çš„ Ctrl+Enter/Command+Enter å¿«æ·é”®ï¼Œæ’å…¥æ¢è¡Œ"""
        # åœ¨å½“å‰å…‰æ ‡ä½ç½®æ’å…¥æ¢è¡Œ
        self.definition_text.insert(tk.INSERT, "\n")
        # è¿”å›"break"é˜»æ­¢äº‹ä»¶ç»§ç»­ä¼ æ’­ï¼ˆé¿å…è§¦å‘å…¶ä»–å…¨å±€ç»‘å®šï¼‰
        return "break"


    # æ–°å¢åŠ©è®°æ¡†æ¢è¡Œå¤„ç†æ–¹æ³•
    def handle_example_newline(self, event):
        """å¤„ç†åŠ©è®°æ¡†çš„ Command+Enter/Ctrl+Enter å¿«æ·é”®ï¼Œæ’å…¥æ¢è¡Œ"""
        self.example_text.insert(tk.INSERT, "\n")
        return "break"

    def on_tree_double(self, event):
        sel = self.tree.selection()
        if not sel: return
        it = sel[0]
        idx = self.tree.index(it)
        item = self.data[idx]
        # populate inputs for edit
        self.word_entry.delete(0, tk.END); self.word_entry.insert(0, item["word"])
        self.phonetic_entry.delete(0, tk.END); self.phonetic_entry.insert(0, item.get("phonetic",""))
        self.pos_entry.delete(0, tk.END); self.pos_entry.insert(0, item.get("pos",""))
        self.definition_text.delete("1.0", tk.END); self.definition_text.insert("1.0", item.get("definition",""))
        self.example_text.delete("1.0", tk.END); self.example_text.insert("1.0", item.get("example",""))
        # remove existing so user can re-add after editing
        del self.data[idx]
        self.tree.delete(it)
        self.status("ç¼–è¾‘æ¨¡å¼ï¼šä¿®æ”¹åç‚¹å‡» æ·»åŠ è¯æ¡ ä¿å­˜æ›´æ”¹")

        #åå°åŠ è½½è¯å…¸
    def _load_dict_in_background(self):
        """åå°åŠ è½½è¯å…¸ï¼Œä¸é˜»å¡UIå¯åŠ¨"""
        if os.path.exists(self.default_dict_path):
            try:
                self.dict_lookup.load(self.default_dict_path)
                # åŠ è½½å®Œæˆåæ›´æ–°çŠ¶æ€æ ï¼ˆé€šè¿‡ä¸»çº¿ç¨‹ï¼‰
                self.root.after(0, lambda: self.status(
                    f"âœ… å·²åŠ è½½æœ¬åœ°è¯å…¸ï¼Œå…± {len(self.dict_lookup.data)} ä¸ªè¯æ¡"
                ))
            except Exception as e:
                self.root.after(0, lambda: self.status(
                    f"âš ï¸ è¯å…¸åŠ è½½å¤±è´¥: {str(e)}"
                ))
        else:
            # æœªæ‰¾åˆ°è¯å…¸æ—¶æ›´æ–°çŠ¶æ€æ 
            self.root.after(0, lambda: self.status(
                "âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°è¯å…¸ï¼Œå¯é€šè¿‡'å¯¼å…¥è¯å…¸'æŒ‰é’®åŠ è½½"
            ))
    # ä¿®æ”¹show_temp_notificationæ–¹æ³•ï¼Œæ·»åŠ Windowsç³»ç»Ÿæ”¯æŒå’Œç›‘å¬çŠ¶æ€åˆ¤æ–­
    def show_temp_notification(self, message):
        """ä»…åœ¨å‰ªè´´æ¿ç›‘å¬æ—¶æ˜¾ç¤ºé€šçŸ¥ï¼Œæ ¹æ®ç³»ç»Ÿé€‰æ‹©åˆé€‚çš„é€šçŸ¥æ–¹å¼"""
        # åªæœ‰åœ¨å‰ªè´´æ¿ç›‘å¬çŠ¶æ€ä¸‹æ‰æ˜¾ç¤ºé€šçŸ¥
        if not self.clipboard_listening:
            return

        if sys.platform == "darwin":
            # macOSä½¿ç”¨AppleScripté€šçŸ¥
            script = f'''
            display notification "{message}" with title "Anki Maker" sound name "default"
            '''
            try:
                subprocess.run(
                    ["osascript", "-e", script],
                    check=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
            except Exception:
                self.status(message)
        elif sys.platform.startswith("win"):
            # Windowsä½¿ç”¨toasté€šçŸ¥
            try:
                from win10toast import ToastNotifier
                toaster = ToastNotifier()
                toaster.show_toast(
                    "Anki Maker",
                    message,
                    duration=3,  # æ˜¾ç¤º3ç§’
                    icon_path=None,  # å¯æ·»åŠ è‡ªå®šä¹‰å›¾æ ‡è·¯å¾„
                    threaded=True
                )
            except ImportError:
                # è‹¥æœªå®‰è£…win10toastï¼Œä½¿ç”¨æ¶ˆæ¯æ¡†
                tk.messagebox.showinfo("Anki Maker", message)
            except Exception as e:
                self.status(f"é€šçŸ¥å¤±è´¥: {message}")
        else:
            # å…¶ä»–ç³»ç»Ÿä½¿ç”¨çŠ¶æ€æ æç¤º
            self.status(message)

    # ---- æ–°å¢çš„åˆ é™¤æ–¹æ³• ----
    def delete_selected_item(self, event=None):
        sel = self.tree.selection()
        if not sel:
            return

        # ä» data åˆ—è¡¨å’Œ tree è§†å›¾ä¸­åŒæ—¶åˆ é™¤
        # å¿…é¡»å€’åºåˆ é™¤ï¼Œé˜²æ­¢ç´¢å¼•å˜åŒ–
        indices_to_delete = []
        items_to_delete_from_tree = []

        for item_id in sel:
            idx = self.tree.index(item_id)
            indices_to_delete.append(idx)
            items_to_delete_from_tree.append(item_id)

        # å€’åºåˆ é™¤ data åˆ—è¡¨
        indices_to_delete.sort(reverse=True)
        for idx in indices_to_delete:
            del self.data[idx]

        # åˆ é™¤ Treeview é¡¹
        for item_id in items_to_delete_from_tree:
            self.tree.delete(item_id)

        self.status(f"å·²åˆ é™¤ {len(indices_to_delete)} æ¡è¯æ¡ã€‚å‰©ä½™ {len(self.data)} æ¡ã€‚")


    # ---- æ–°å¢çš„æ¸…ç©ºæ–¹æ³• ----
    def clear_all_items(self):
        if not self.data:
            return
        if messagebox.askyesno("âš ï¸ ç¡®è®¤æ¸…ç©º", f"ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ {len(self.data)} æ¡è¯æ¡å—ï¼Ÿ\næ­¤æ“ä½œä¸å¯æ’¤é”€ï¼"):
            self.data = []
            self.tree.delete(*self.tree.get_children())
            self.status("å·²æ¸…ç©ºæ‰€æœ‰è¯æ¡")
            self.save_draft()  # æ¸…ç©ºåç«‹å³ä¿å­˜


    # ---------------- Search ----------------
    def filter_tree(self, event=None):
        q = self.search_var.get().strip().lower()
        self.tree.delete(*self.tree.get_children())
        for it in self.data:
            if not q or q in it.get("word", "").lower() or q in it.get("definition", "").lower():
                self._tree_insert(it)

    # ---------------- Export ----------------
    def export_csv(self):
        if not self.data:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ è¯æ¡")
            return

        ensure_export_folder()
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        path = os.path.join(EXPORT_FOLDER, f"anki_vocab_{ts}.csv")

        # åœ¨fieldnamesä¸­æ·»åŠ 'mnemonic'å­—æ®µ
        with open(path, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["word", "phonetic", "pos", "definition", "example", "mnemonic"])
            writer.writeheader()
            for it in self.data:
                writer.writerow(it)

        open_folder(os.path.abspath(EXPORT_FOLDER))
        self.status(f"å·²å¯¼å‡º CSVï¼š{os.path.basename(path)}")

    def export_json(self):
        if not self.data:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ è¯æ¡")
            return

        ensure_export_folder()
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        path = os.path.join(EXPORT_FOLDER, f"anki_vocab_{ts}.json")

        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)

        open_folder(os.path.abspath(EXPORT_FOLDER))
        self.status(f"å·²å¯¼å‡º JSONï¼š{os.path.basename(path)}")



    def export_apkg(self):
        if not self.data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å•è¯å¯å¯¼å‡ºï¼")
            return

        ensure_export_folder()
        deck = genanki.Deck(1984567890, "My Vocabulary")

        for it in self.data:  # âœ… è¿™é‡Œç”¨ self.data è€Œä¸æ˜¯ self.words
            note = genanki.Note(
                model=vocab_model,  # ä½ è‡ªå·±å®šä¹‰çš„ model
                fields=[
                    it['word'],
                    it.get('phonetic',''),
                    it.get('pos',''),
                    it.get('definition',''),
                    it.get('example','')
                ]
            )
            deck.add_note(note)

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_path = os.path.join(EXPORT_FOLDER, f"anki_vocab_{ts}.apkg")

        try:
            genanki.Package(deck).write_to_file(file_path)
            self.status(f"å·²å¯¼å‡º APKG: {file_path}")
            open_folder(os.path.abspath(EXPORT_FOLDER))
            messagebox.showinfo("æˆåŠŸ", f"å¡ç»„å·²ä¿å­˜åˆ°ï¼š\n{file_path}")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥ï¼š{e}")


    def export_md(self):
        if not self.data:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ è¯æ¡")
            return

        ensure_export_folder()
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        path = os.path.join(EXPORT_FOLDER, f"anki_vocab_{ts}.md")

        # å®šä¹‰è½¬ä¹‰å‡½æ•°ï¼Œç»™ [ å’Œ ] å‰æ·»åŠ åæ–œæ 
        def escape_brackets(text):
            if not text:
                return ""
            return text.replace("[", "\\[").replace("]", "\\]")

        with open(path, "w", encoding="utf-8") as f:
            for it in self.data:
                # å¯¹æ‰€æœ‰å¯èƒ½åŒ…å«[]çš„å­—æ®µè¿›è¡Œè½¬ä¹‰å¤„ç†
                word = escape_brackets(it['word'])
                phonetic = escape_brackets(it.get('phonetic', ''))
                pos = escape_brackets(it.get('pos', ''))
                definition = escape_brackets(it.get('definition', ''))
                example = escape_brackets(it.get('example', ''))

                f.write(f"### =={word}==\n")
                if phonetic:
                    f.write(f"**éŸ³æ ‡**: {phonetic}\n")
                if pos:
                    f.write(f"**è¯æ€§**: {pos}\n")
                f.write(f"**é‡Šä¹‰**: {definition}\n")
                if example:
                    f.write(f"**åŠ©è®°**: {example}\n")
                f.write("\n---\n\n")

        open_folder(os.path.abspath(EXPORT_FOLDER))
        self.status(f"å·²å¯¼å‡º MDï¼š{os.path.basename(path)}")

    def toggle_clipboard_listen(self):
        """åˆ‡æ¢å‰ªè´´æ¿ç›‘å¬çŠ¶æ€"""
        if self.clipboard_listening:
            self.clipboard_listening = False
            self.status("å·²å…³é—­å‰ªè´´æ¿ç›‘å¬")
        else:
            self.clipboard_listening = True
            self.status("å·²å¼€å¯å‰ªè´´æ¿ç›‘å¬...")
            # å¯åŠ¨ç›‘å¬çº¿ç¨‹
            threading.Thread(target=self.clipboard_listen_loop, daemon=True).start()

    def start_clipboard_listen(self):
        self.clipboard_listening = True
        self.last_clipboard_content = ""
        self._poll_clipboard()


    def import_txt_file(self):
        """å¯¼å…¥TXTæ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªå•è¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ‰¹é‡å¤„ç†ï¼Œä¸æ˜¾ç¤ºä¸­é—´è¿‡ç¨‹ï¼‰"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©TXTæ–‡ä»¶",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if not file_path:
            return

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                words = [line.strip() for line in f if line.strip() and line.strip().isalpha()]
            
            if not words:
                messagebox.showinfo("æç¤º", "æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„è‹±æ–‡å•è¯")
                return

            self.status(f"å¼€å§‹å¯¼å…¥ {len(words)} ä¸ªå•è¯...")
            
            # æ‰¹é‡å¤„ç†å•è¯ï¼ˆä¸æ›´æ–°UIï¼Œåªå¤„ç†æ•°æ®ï¼‰
            success = 0
            fail = 0
            new_items = []
            
            for word in words:
                # æŸ¥æ‰¾è¯å…¸
                res = self.dict_lookup.lookup(word)
                
                # æ„å»ºè¯æ¡æ•°æ®
                phon = ""
                pos = ""
                definition = ""
                
                if res:
                    phon = res.get("phonetic", "")
                    pos = res.get("pos", "")
                    trans = res.get("translations", []) or []
                    definition = "\n".join(trans) if trans else "\n".join(d for d in res.get("definitions", []) or [])
                    success += 1
                else:
                    fail += 1
                
                # æ·»åŠ åˆ°ä¸´æ—¶åˆ—è¡¨
                new_items.append({
                    "word": word,
                    "phonetic": phon,
                    "pos": pos,
                    "definition": definition,
                    "example": ""
                })
            
            # ä¸€æ¬¡æ€§æ›´æ–°æ•°æ®å’ŒUI
            self.data.extend(new_items)
            
            # æ¸…ç©ºç°æœ‰æ ‘çŠ¶è§†å›¾å¹¶æ‰¹é‡æ’å…¥æ–°æ•°æ®
            self.tree.delete(*self.tree.get_children())
            for item in self.data:
                self._tree_insert(item)
            
            # ä¿å­˜è‰ç¨¿
            self.save_draft()
            
            self.status(f"å¯¼å…¥å®Œæˆï¼æˆåŠŸ: {success}, å¤±è´¥: {fail} (å…± {len(words)} ä¸ªå•è¯)")
            messagebox.showinfo("å¯¼å…¥ç»“æœ", 
                            f"å…±å¤„ç† {len(words)} ä¸ªå•è¯\n"
                            f"æˆåŠŸè·å–ä¿¡æ¯: {success}ä¸ª\n"
                            f"æœªåœ¨è¯å…¸ä¸­æ‰¾åˆ°: {fail}ä¸ª")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å…¥å¤±è´¥: {str(e)}")
    def _parse_and_add_from_txt(self, path):
        """åå°è¯»å– txtï¼Œæ¯è¡Œä¸€ä¸ªå•è¯ï¼Œè‡ªåŠ¨è¡¥å…¨å¹¶æ·»åŠ åˆ° data åˆ—è¡¨"""
        try:
            with open(path, "r", encoding="utf-8") as f:
                lines = f.readlines()
        except Exception as e:
            # å›ä¸»çº¿ç¨‹å¼¹çª—/çŠ¶æ€æ›´æ–°
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ‰“å¼€æ–‡ä»¶å¤±è´¥: {e}"))
            self.root.after(0, lambda: self.status("TXT å¯¼å…¥å¤±è´¥"))
            return

        # é¢„å¤„ç†ï¼šé€è¡Œæ¸…ç†å¹¶å»é‡ï¼ˆä¿ç•™åŸé¡ºåºï¼‰
        seen = set()
        words = []
        for ln in lines:
            w = ln.strip()
            if not w:
                continue
            # åªè€ƒè™‘å•ä¸ªè‹±æ–‡å•è¯ï¼ˆå¯åŒ…å«æ’‡å·æˆ–è¿å­—ç¬¦ï¼‰
            if not self.is_single_english_word(w):
                continue
            key = w.lower()
            if key in seen:
                continue
            seen.add(key)
            words.append(w)

        if not words:
            self.root.after(0, lambda: messagebox.showinfo("æç¤º", "æœªæ£€æµ‹åˆ°æœ‰æ•ˆå•è¯"))
            self.root.after(0, lambda: self.status("æœªæ£€æµ‹åˆ°æœ‰æ•ˆå•è¯"))
            return

        added = 0
        # å¯¹æ¯ä¸ªå•è¯åœ¨ä¸»çº¿ç¨‹ä¸­å¡«å……å¹¶æ·»åŠ ï¼ˆå› ä¸ºæ¶‰åŠ UI æ“ä½œï¼‰
        for i, w in enumerate(words, start=1):
            def do_one(word=w):
                # å¡«å…¥è¾“å…¥æ¡†
                self.word_entry.delete(0, tk.END)
                self.word_entry.insert(0, word)
                # å°è¯•ç”¨æœ¬åœ°è¯å…¸è‡ªåŠ¨è¡¥å…¨ï¼ˆä¼šè¦†ç›–éŸ³æ ‡ä¸é‡Šä¹‰ï¼‰
                try:
                    self.autofill_from_dict()
                except Exception:
                    pass
                # æ·»åŠ åˆ°æ•°æ®ï¼ˆæ ‡è®°ä¸ºè‡ªåŠ¨æ·»åŠ ä¸”è·³è¿‡éªŒè¯ï¼‰
                try:
                    self.add_word(is_auto=True, skip_validation=True)  # å¢åŠ å‚æ•°
                except Exception:
                    # è‹¥æŸæ¡æ·»åŠ å¤±è´¥ï¼Œå¿½ç•¥ç»§ç»­
                    pass
            # åœ¨ä¸»çº¿ç¨‹åš UI æ“ä½œ
            self.root.after(0, do_one)
            added += 1
            # å¾®å°å»¶è¿Ÿä»¥é¿å… UI åˆ·æ–°å‹åŠ›ï¼ˆéé˜»å¡ï¼‰
            time.sleep(0.05)

        # å®Œæˆåé€šçŸ¥ç”¨æˆ·ï¼ˆä¸»çº¿ç¨‹ï¼‰
        self.root.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"å·²å¯¼å…¥ {added} ä¸ªå•è¯å¹¶ç”Ÿæˆå¡ç‰‡"))
        self.root.after(0, lambda: self.status(f"å·²ä» TXT å¯¼å…¥ {added} ä¸ªå•è¯"))







    def _poll_clipboard(self):
        if not self.clipboard_listening:
            return
        try:
            current = self.root.clipboard_get().strip()
            if current and current != self.last_clipboard_content and self.is_single_english_word(current):
                self.last_clipboard_content = current
                self.process_clipboard_word(current)
        except Exception:
            pass
        # æ¯500msæ£€æŸ¥ä¸€æ¬¡ï¼Œæ¯”sleepæ›´å“åº”UI
        self.root.after(500, self._poll_clipboard)

    def toggle_clipboard_listen(self):
        if self.clipboard_listening:
            self.clipboard_listening = False
            self.status("å·²å…³é—­å‰ªè´´æ¿ç›‘å¬")
        else:
            self.start_clipboard_listen()
            self.status("å·²å¼€å¯å‰ªè´´æ¿ç›‘å¬...")

    def is_single_english_word(self, text):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå•ä¸ªè‹±æ–‡å•è¯"""
        # ä»…åŒ…å«å­—æ¯ï¼Œå¯èƒ½åŒ…å«æ’‡å·ï¼ˆå¦‚don'tï¼‰æˆ–è¿å­—ç¬¦ï¼ˆå¦‚mother-in-lawï¼‰
        return bool(re.fullmatch(r"[a-zA-Z'-]+", text))

    def process_clipboard_word(self, word):
        """å¤„ç†å‰ªè´´æ¿è·å–çš„å•è¯"""
        # å¡«å……å•è¯åˆ°è¾“å…¥æ¡†
        self.word_entry.delete(0, tk.END)
        self.word_entry.insert(0, word)
        
        # è‡ªåŠ¨è¡¥å…¨å•è¯ä¿¡æ¯
        self.autofill_from_dict()
        
        # è‡ªåŠ¨æ·»åŠ åˆ°åˆ—è¡¨ï¼Œæ ‡è®°ä¸ºè‡ªåŠ¨æ·»åŠ 
        self.add_word(is_auto=True)
        
        self.status(f"ä»å‰ªè´´æ¿æ·»åŠ å•è¯: {word}")
    # ---------------- Draft / Autosave ----------------
    def save_draft(self):
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        self.status(f"å·²æš‚å­˜è‰ç¨¿ ({len(self.data)} æ¡)")

    def _load_draft(self):
        def load_in_thread():
            if os.path.exists(DATA_FILE):
                try:
                    with open(DATA_FILE, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    # å›åˆ°ä¸»çº¿ç¨‹æ›´æ–°UI
                    self.root.after(0, lambda: self._update_draft_ui(data))
                except Exception:
                    pass

        threading.Thread(target=load_in_thread, daemon=True).start()

    def _update_draft_ui(self, data):
        self.data = data
        for it in self.data:
            self._tree_insert(it)
        self.status(f"å·²åŠ è½½è‰ç¨¿ ({len(self.data)} æ¡)")


    def select_md_file(self):
        """é€‰æ‹©å¹¶å¤„ç† MD æ–‡ä»¶"""
        path = filedialog.askopenfilename(filetypes=[("Markdown files", "*.md"), ("All files", "*.*")])
        if not path:
            return

        self.status("æ­£åœ¨å¤„ç† MD æ–‡ä»¶...")
        # ç”¨çº¿ç¨‹å¤„ç†ï¼Œé¿å… UI å¡é¡¿
        threading.Thread(target=self._process_md_thread, args=(path,), daemon=True).start()

    def _process_md_thread(self, md_path):
        """åå°çº¿ç¨‹å¤„ç† MD æ–‡ä»¶"""
        filtered_words, error = process_md_file(md_path)
        if error:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error))
            self.root.after(0, lambda: self.status("å¤„ç†å¤±è´¥"))
            return

        # å¤„ç†å®Œæˆåæ˜¾ç¤ºç»“æœ
        self.root.after(0, lambda: self.show_md_result(filtered_words, md_path))
        self.root.after(0, lambda: self.status(f"å¤„ç†å®Œæˆï¼Œå…±æå– {len(filtered_words)} ä¸ªå•è¯"))

    def show_md_result(self, filtered_words, md_path):
        """æ˜¾ç¤º MD å¤„ç†ç»“æœçš„çª—å£"""
        win = tk.Toplevel(self.root)  # ä¿å­˜çª—å£å¼•ç”¨
        win.title(f"MD æå–ç»“æœ - {os.path.basename(md_path)}")
        win.geometry("600x400")
        win.transient(self.root)  # ç½®äºä¸»çª—å£ä¹‹ä¸Š

        # ç»“æœæ–‡æœ¬åŒº
        text_area = scrolledtext.ScrolledText(win, wrap=tk.WORD)
        text_area.pack(expand=True, fill=tk.BOTH, padx=10, pady=10)
        text_area.insert(tk.END, "\n".join(filtered_words))
        text_area.configure(state='disabled')

        # æ·»åŠ "æ‰¹é‡å¯¼å…¥å•è¯"æŒ‰é’®
        btn_frame = ttk.Frame(win)
        btn_frame.pack(pady=10)
        
        # ä¿®æ”¹æŒ‰é’®å›è°ƒï¼Œæ·»åŠ å…³é—­çª—å£çš„é€»è¾‘
        def batch_import_and_close():
            self.batch_add_from_md(filtered_words)  # æ‰§è¡Œå¯¼å…¥
            win.destroy()  # å…³é—­çª—å£
        
        ttk.Button(
            btn_frame,
            text="æ‰¹é‡å¯¼å…¥åˆ°å•è¯åˆ—è¡¨",
            command=batch_import_and_close  # ä½¿ç”¨æ–°çš„å›è°ƒå‡½æ•°
        ).pack()


    def batch_add_from_md(self, words):
        """å°†æå–çš„å•è¯æ‰¹é‡æ·»åŠ åˆ° Anki åˆ—è¡¨ï¼ˆè‡ªåŠ¨è¡¥å…¨ä¿¡æ¯ï¼‰"""
        for word in words:
            # è‡ªåŠ¨è¡¥å…¨å•è¯ä¿¡æ¯ï¼ˆå¤ç”¨ç°æœ‰è‡ªåŠ¨è¡¥å…¨é€»è¾‘ï¼‰
            self.word_entry.delete(0, tk.END)
            self.word_entry.insert(0, word)
            self.autofill_from_dict()  # è°ƒç”¨ç°æœ‰è‡ªåŠ¨è¡¥å…¨æ–¹æ³•
            # æ·»åŠ åˆ°åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
            word = self.word_entry.get().strip()
            phonetic = self.phonetic_entry.get().strip()
            pos = self.pos_entry.get().strip()
            definition = self.definition_text.get("1.0", tk.END).strip()
            mnemonic = self.example_text.get("1.0", tk.END).strip()
            if word:  # åªæ·»åŠ éç©ºå•è¯
                self.data.append({
                    "word": word,
                    "phonetic": phonetic,
                    "pos": pos,
                    "definition": definition,
                    "mnemonic": mnemonic
                })
        # åˆ·æ–°åˆ—è¡¨æ˜¾ç¤º
        self.refresh_treeview()
        # ç®€åŒ–æç¤ºä¿¡æ¯ï¼Œé¿å…é‡å¤å¼¹çª—
        self.status(f"å·²å¯¼å…¥ {len(words)} ä¸ªå•è¯ï¼ˆç©ºå€¼å·²è¿‡æ»¤ï¼‰")



    def import_json_draft(self):
        p = filedialog.askopenfilename(title="é€‰æ‹© JSON è‰ç¨¿", filetypes=[("JSON", "*.json"), ("All files", "*.*")])
        if p:
            try:
                with open(p, "r", encoding="utf-8") as f:
                    self.data = json.load(f)
                self.tree.delete(*self.tree.get_children())
                for it in self.data:
                    self._tree_insert(it)
                self.status(f"å·²å¯¼å…¥ JSON è‰ç¨¿ ({len(self.data)} æ¡)")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"åŠ è½½å¤±è´¥: {e}")

    def _autosave_loop(self):
        while self.autosave_running:
            time.sleep(AUTOSAVE_INTERVAL)
            if self.data:
                self.save_draft()

    def _start_autosave(self):
        t = threading.Thread(target=self._autosave_loop, daemon=True)
        t.start()


    # ---------------- Search ----------------
    def filter_tree(self, event=None):
        q = self.search_var.get().strip().lower()
        self.tree.delete(*self.tree.get_children())
        for it in self.data:
            if not q or q in it.get("word", "").lower() or q in it.get("definition", "").lower():
                self._tree_insert(it)

    # ---------------- tutorial ----------------
    def show_tutorial(self):
        """æ˜¾ç¤ºä½¿ç”¨æ•™ç¨‹çª—å£"""
        tutorial_window = TutorialWindow(self.root)
        self.root.wait_window(tutorial_window)


    # ---------------- Close ----------------
    def on_close(self):
        self.autosave_running = False
        self.save_draft()
        self.root.destroy()


# ---------------- Main ----------------
def main():
    root = tk.Tk()
    app = AnkiMakerApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
